{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import glob\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import sys\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "from keras.callbacks import EarlyStopping\n",
    "from scipy import stats\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate(df, index_list, col):\n",
    "    count = len(index_list)\n",
    "    \n",
    "    before_index = index_list[0] - 1\n",
    "    before_val = df.loc[before_index,col]\n",
    "    \n",
    "    after_index = index_list[len(index_list)-1] + 1\n",
    "    after_val = df.loc[after_index,col]\n",
    "    \n",
    "    inc_amount = (after_val - before_val) / (count + 1)\n",
    "    \n",
    "    for i in range(count):\n",
    "        update_index = index_list[i]\n",
    "        update_val = df.loc[update_index-1,col] + inc_amount\n",
    "        df.loc[update_index,col] = update_val\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"data/Protocol/\"\n",
    "files_path = data_folder + \"subject*.dat\"\n",
    "\n",
    "# ====================\n",
    "#files_path = data_folder + \"subject101.dat\"\n",
    "# ====================\n",
    "\n",
    "df_main = pd.DataFrame(columns=['exp_id','label_id','acc0','acc1','acc2','gyro0','gyro1','gyro2'])\n",
    "\n",
    "files = glob.glob(files_path)\n",
    "for file in files:\n",
    "    df_exp = pd.read_csv(file, header=None, delimiter=r\"\\s+\")\n",
    "    df_exp_filtered = df_exp.filter([1, 4, 5, 6, 10, 11, 12])\n",
    "    df_exp_filtered.columns = ['label_id','acc0','acc1','acc2','gyro0','gyro1','gyro2']\n",
    "    \n",
    "    exp_id = int(file[23])\n",
    "    df_exp_filtered['exp_id'] = exp_id\n",
    "    \n",
    "    if exp_id==9:\n",
    "        continue\n",
    "    \n",
    "    cols=['exp_id','label_id','acc0','acc1','acc2','gyro0','gyro1','gyro2']\n",
    "    df_exp_filtered = df_exp_filtered[cols]\n",
    "    \n",
    "    total_rows = len(df_exp_filtered)\n",
    "    interpol_cols = ['acc0','acc1','acc2','gyro0','gyro1','gyro2']\n",
    "    for col in interpol_cols:\n",
    "        index = 0\n",
    "        while index < total_rows:\n",
    "            if math.isnan(df_exp_filtered.loc[index,col]):\n",
    "                index_list = [index]\n",
    "                nan_index = index + 1\n",
    "                while (True):\n",
    "                    if math.isnan(df_exp_filtered.loc[nan_index,col]):\n",
    "                        index_list.append(nan_index)\n",
    "                        nan_index += 1\n",
    "                    else:\n",
    "                        break\n",
    "                df_exp_filtered = interpolate(df_exp_filtered, index_list, col)\n",
    "            index += 1\n",
    "    \n",
    "    df_main = df_main.append(df_exp_filtered, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test interpolate for exp 1\n",
    "# df_exp_filtered[19190:19199]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 512\n",
    "window_move_size = 100 #window_size // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(df_OVA):\n",
    "\n",
    "    curr_index = 0\n",
    "    act_start_index = 0\n",
    "    act_end_index = 0\n",
    "\n",
    "    df_OVA_trimmed = pd.DataFrame(columns=['exp_id','label_id','acc0','acc1','acc2','gyro0','gyro1','gyro2'])\n",
    "\n",
    "    while (True):\n",
    "        curr_act_id = df_OVA.loc[act_start_index, 'label_id']\n",
    "    \n",
    "        curr_index = act_start_index + 1\n",
    "        while (True):\n",
    "            act_id = df_OVA.loc[curr_index, 'label_id']\n",
    "            if (act_id != curr_act_id):\n",
    "                act_end_index = curr_index - 1\n",
    "                break\n",
    "            elif curr_index == (len(df_OVA) - 1):\n",
    "                act_end_index = curr_index\n",
    "                break\n",
    "            else:\n",
    "                curr_index += 1\n",
    "            \n",
    "        df_act_trimmed = df_OVA[act_start_index + 1000 : act_end_index - 1000]\n",
    "    \n",
    "        if len(df_act_trimmed) > 0:\n",
    "            df_OVA_trimmed = df_OVA_trimmed.append(df_act_trimmed, ignore_index = True)\n",
    "            #df_OVA_trimmed = df_OVA_trimmed.reset_index(drop=True)\n",
    "    \n",
    "        if curr_index >= (len(df_OVA) - 1):\n",
    "            break\n",
    "        else:\n",
    "            act_start_index = act_end_index + 1\n",
    "    \n",
    "    return df_OVA_trimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment(df_OVA):\n",
    "\n",
    "    segmeneted_activities = [ 'N/A',[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[] ]\n",
    "\n",
    "    for i in range(1 , 9):\n",
    "\n",
    "        df_exp = df_OVA.loc[df_OVA['exp_id'] == i]\n",
    "        df_exp = df_exp.reset_index(drop=True)\n",
    "\n",
    "        index = 0\n",
    "        continu = True\n",
    "        while (continu):\n",
    "\n",
    "            if index >= len(df_exp):\n",
    "                break\n",
    "\n",
    "            df_window = df_exp.loc[index:index+window_size-1]\n",
    "            if len(df_window) < window_size:\n",
    "                break\n",
    "\n",
    "            window_label_ids = set(df_window['label_id'].values)\n",
    "            if (len(window_label_ids) > 1) or \\\n",
    "               (len(window_label_ids)==1 and next(iter(window_label_ids))==0):\n",
    "                index = index + window_move_size\n",
    "                continue\n",
    "\n",
    "            na_window = np.array((df_window.loc[:,'acc0':'gyro2']))\n",
    "            window_label_id = next(iter(window_label_ids))\n",
    "\n",
    "            segmeneted_activities[window_label_id].append(na_window)\n",
    "            index = index + window_move_size\n",
    "\n",
    "    for i in range(1,25):\n",
    "        segmeneted_activities[i] = np.array(segmeneted_activities[i])\n",
    "        \n",
    "    for i in range(1,25):\n",
    "        print (\"Act_id:\" , i , \" \" , segmeneted_activities[i].shape)\n",
    "        \n",
    "    return segmeneted_activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binary_X_and_Y (act_id , segmeneted_activities):\n",
    "\n",
    "    X = np.concatenate((segmeneted_activities[1], segmeneted_activities[2]))\n",
    "    X = np.concatenate((           X            , segmeneted_activities[3]))\n",
    "    X = np.concatenate((           X            , segmeneted_activities[17]))\n",
    "    X = np.concatenate((           X            , segmeneted_activities[16]))\n",
    "    X = np.concatenate((           X            , segmeneted_activities[12]))\n",
    "    X = np.concatenate((           X            , segmeneted_activities[13]))\n",
    "    X = np.concatenate((           X            , segmeneted_activities[4]))\n",
    "    X = np.concatenate((           X            , segmeneted_activities[7]))\n",
    "    X = np.concatenate((           X            , segmeneted_activities[6]))\n",
    "    X = np.concatenate((           X            , segmeneted_activities[5]))\n",
    "    X = np.concatenate((           X            , segmeneted_activities[24]))\n",
    "\n",
    "    ys = ['N/A',None,None,None,None,None,None,None,None,None,None,None, \\\n",
    "          None,None,None,None,None,None,None,None,None,None,None,None,None]\n",
    "    for i in range(1,25):\n",
    "        size = segmeneted_activities[i].shape[0]\n",
    "        if act_id == i:\n",
    "            y = np.full (size , 1)\n",
    "        else:\n",
    "            y = np.full (size , 0)\n",
    "        ys[i] = y\n",
    "\n",
    "    Y = np.concatenate((ys[1], ys[2]))\n",
    "    Y = np.concatenate((  Y  , ys[3]))\n",
    "    Y = np.concatenate((  Y  , ys[17]))\n",
    "    Y = np.concatenate((  Y  , ys[16]))\n",
    "    Y = np.concatenate((  Y  , ys[12]))\n",
    "    Y = np.concatenate((  Y  , ys[13]))\n",
    "    Y = np.concatenate((  Y  , ys[4]))\n",
    "    Y = np.concatenate((  Y  , ys[7]))\n",
    "    Y = np.concatenate((  Y  , ys[6]))\n",
    "    Y = np.concatenate((  Y  , ys[5]))\n",
    "    Y = np.concatenate((  Y  , ys[24]))\n",
    "\n",
    "    return (X , Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model (data_input_shape):\n",
    "\n",
    "    LSTM_output_dim = 100\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    #model.add(LSTM(LSTM_output_dim, return_sequences=True, name='LSTM1', input_shape=data_input_shape))    \n",
    "    #model.add(LSTM(LSTM_output_dim, return_sequences=True, name='LSTM2'))\n",
    "    #model.add(LSTM(LSTM_output_dim, return_sequences=False, name='LSTM3'))\n",
    "    \n",
    "    model.add(LSTM(LSTM_output_dim, return_sequences=False, name='LSTM1', input_shape=data_input_shape))\n",
    "    \n",
    "    model.add(Dense(15, activation='sigmoid',name='Hidden_Layer'))\n",
    "    \n",
    "    #model.add(Dense(3, activation='softmax', name='Softmax_layer'))\n",
    "    model.add(Dense(1, activation='sigmoid',name='Dense_out'))\n",
    "    \n",
    "    #model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_binary_classifier(act_id, segmeneted_activities):\n",
    "    (X , Y) = get_binary_X_and_Y (act_id , segmeneted_activities)\n",
    "    \n",
    "    X , Y = shuffle(X , Y)\n",
    "\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.25)\n",
    "    X_train,X_valid,y_train,y_valid=train_test_split(X_train,y_train,test_size=0.333)\n",
    "\n",
    "    data_input_shape = X.shape[1:3]\n",
    "    model = create_model(data_input_shape)\n",
    "    #print (model.summary()  , \"\\n\")\n",
    "\n",
    "    patience = 5\n",
    "    callbacks=[EarlyStopping(monitor='val_loss',patience=patience,verbose=1)]\n",
    "    history = model.fit(X_train,y_train,\n",
    "                        validation_data=[X_valid,y_valid],\n",
    "                        epochs=15, \n",
    "                        batch_size=100,\n",
    "                        verbose=2\n",
    "                        ,callbacks=callbacks\n",
    "                       )\n",
    "\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('\\nTest loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    print ()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df_OVA):\n",
    "    df_OVA = trim(df_OVA)\n",
    "    \n",
    "    segmeneted_activities = segment(df_OVA)\n",
    "    \n",
    "    #training binary classifier for activity 1 (Lying)\n",
    "    print ()\n",
    "    print (\"Training activity 1 ...\")\n",
    "    act_id = 1\n",
    "    model_1 = train_binary_classifier(act_id, segmeneted_activities)\n",
    "    #model_1.save('model512_1.h5')\n",
    "    \n",
    "    #training binary classifier for activity 2 (Sitting)\n",
    "    print (\"Training activity 2 ...\")\n",
    "    act_id = 2\n",
    "    model_2 = train_binary_classifier(act_id, segmeneted_activities)\n",
    "    #model_2.save('model512_2.h5')\n",
    "\n",
    "    #training binary classifier for activity 3 (Standing)\n",
    "    print (\"Training activity 3 ...\")\n",
    "    act_id = 3\n",
    "    model_3 = train_binary_classifier(act_id, segmeneted_activities)\n",
    "    #model_3.save('model512_3.h5')\n",
    "    \n",
    "    #training binary classifier for activity 17 (Ironing)\n",
    "    print (\"Training activity 17 ...\")\n",
    "    act_id = 17\n",
    "    model_17 = train_binary_classifier(act_id, segmeneted_activities)\n",
    "    #model_17.save('model512_17.h5')\n",
    "    \n",
    "    #training binary classifier for activity 16 (Vacuum Cleaning)\n",
    "    print (\"Training activity 16 ...\")\n",
    "    act_id = 16\n",
    "    model_16 = train_binary_classifier(act_id, segmeneted_activities)\n",
    "    #model_16.save('model512_16.h5')\n",
    "    \n",
    "    #training binary classifier for activity 12 (Ascending Stairs)\n",
    "    print (\"Training activity 12 ...\")\n",
    "    act_id = 12\n",
    "    model_12 = train_binary_classifier(act_id, segmeneted_activities)\n",
    "    #model_12.save('model512_12.h5')\n",
    "    \n",
    "    #training binary classifier for activity 13 (Descending Stairs)\n",
    "    print (\"Training activity 13 ...\")\n",
    "    act_id = 13\n",
    "    model_13 = train_binary_classifier(act_id, segmeneted_activities)\n",
    "    #model_13.save('model512_13.h5')\n",
    "    \n",
    "    #training binary classifier for activity 4 (Walking)\n",
    "    print (\"Training activity 4 ...\")\n",
    "    act_id = 4\n",
    "    model_4 = train_binary_classifier(act_id, segmeneted_activities)\n",
    "    #model_4.save('model512_4.h5')\n",
    "    \n",
    "    #training binary classifier for activity 7 (Nordic Walking)\n",
    "    print (\"Training activity 7 ...\")\n",
    "    act_id = 7\n",
    "    model_7 = train_binary_classifier(act_id, segmeneted_activities)\n",
    "    #model_7.save('model512_7.h5')\n",
    "    \n",
    "    #training binary classifier for activity 6 (Cycling)\n",
    "    print (\"Training activity 6 ...\")\n",
    "    act_id = 6\n",
    "    model_6 = train_binary_classifier(act_id, segmeneted_activities)\n",
    "    #model_6.save('model512_6.h5')\n",
    "    \n",
    "    #training binary classifier for activity 5 (Running)\n",
    "    print (\"Training activity 5 ...\")\n",
    "    act_id = 5\n",
    "    model_5 = train_binary_classifier(act_id, segmeneted_activities)\n",
    "    #model_5.save('model512_5.h5')\n",
    "    \n",
    "    #training binary classifier for activity 24 (Rope Jumping)\n",
    "    print (\"Training activity 24 ...\")\n",
    "    act_id = 24\n",
    "    model_24 = train_binary_classifier(act_id, segmeneted_activities)\n",
    "    #model_24.save('model512_24.h5')\n",
    "    \n",
    "    models = [None,None,None,None,None,None,None,None,None,None,None,None, \\\n",
    "              None,None,None,None,None,None,None,None,None,None,None,None,None]\n",
    "    models[1] = model_1\n",
    "    models[2] = model_2\n",
    "    models[3] = model_3\n",
    "    models[17] = model_17\n",
    "    models[16] = model_16\n",
    "    models[12] = model_12\n",
    "    models[13] = model_13\n",
    "    models[4] = model_4\n",
    "    models[7] = model_7\n",
    "    models[6] = model_6\n",
    "    models[5] = model_5\n",
    "    models[24] = model_24\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "# model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_predict):\n",
    "\n",
    "    X_predict = np.reshape(X_predict , (1,X_predict.shape[0],X_predict.shape[1]))\n",
    "\n",
    "    scores = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "    for i in range(24):\n",
    "        model = models[i+1]\n",
    "        if (model is not None):\n",
    "            pred_probs = model.predict_proba(X_predict)\n",
    "            scores[i] = pred_probs[0][0]\n",
    "\n",
    "    threshold = 0.5\n",
    "    if max(scores) < threshold:\n",
    "        label_id = 0\n",
    "    else:\n",
    "        label_id = scores.index(max(scores)) + 1\n",
    "    \n",
    "    return label_id, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(df_continuous , models):\n",
    "\n",
    "    # =================\n",
    "    #df_continuous2 = df_continuous.loc[df_continuous['exp_id'] == 7]\n",
    "    df_continuous2 = df_continuous\n",
    "    # =================\n",
    "\n",
    "    index = 0\n",
    "    continu = True\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "    while (continu):\n",
    "\n",
    "        if index >= len(df_continuous2):\n",
    "            break\n",
    "\n",
    "        df_window = df_continuous2.loc[index:index+window_size-1]\n",
    "        if len(df_window) < window_size:\n",
    "            break\n",
    "\n",
    "        mode_win_labels = stats.mode(df_window['label_id'].values)\n",
    "        window_label_id = mode_win_labels[0][0]\n",
    "\n",
    "        if window_label_id == 0:\n",
    "            print (\"Window Label: 0\")\n",
    "            index = index + window_move_size\n",
    "            continue\n",
    "\n",
    "        na_window = np.array((df_window.loc[:,'acc0':'gyro2']))\n",
    "        pred_label_id, _ = predict(na_window)\n",
    "\n",
    "        print (\"Window Label: \" + str(window_label_id) + \"  Predicted Label: \" + str(pred_label_id))\n",
    "        \n",
    "        total_preds += 1\n",
    "\n",
    "        if (pred_label_id == window_label_id):\n",
    "            correct_preds += 1\n",
    "\n",
    "        index = index + window_move_size\n",
    "            \n",
    "    accu = correct_preds/total_preds\n",
    "    print (\"\\nContinuous Accuracy: \" + str(accu))\n",
    "    return accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_accu = [0,0,0,0,0,0,0,0]\n",
    "for i in range(1,9):\n",
    "    split_exp_id = i\n",
    "    df_continuous = df_main.loc[df_main['exp_id'] == split_exp_id]\n",
    "    df_continuous = df_continuous.reset_index(drop=True)\n",
    "\n",
    "    df_OVA = df_main.loc[df_main['exp_id'] != split_exp_id]\n",
    "    df_OVA = df_OVA.reset_index(drop=True)\n",
    "\n",
    "    print (\"fold\" , i , \"Training:\")\n",
    "    print (\"len of df_main:\" , str(len(df_main)))\n",
    "    print (\"len of df_continuous:\" , str(len(df_continuous)))\n",
    "    print (\"len of df_OVA:\" , str(len(df_OVA)))\n",
    "    print ()\n",
    "    \n",
    "    models = train(df_OVA)\n",
    "    \n",
    "    print (\"\\nfold\" , i , \"Testing:\")\n",
    "    accu = test(df_continuous, models)\n",
    "    folds_accu[i-1] = accu\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum = 0\n",
    "for i in range(len(folds_accu)):\n",
    "    sum += folds_accu[i]\n",
    "    \n",
    "avg_accu = sum / len(folds_accu)\n",
    "print (\"\\nAverage Accuracy for all folds:\" , avg_accu)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import glob\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import sys\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "from keras.callbacks import EarlyStopping\n",
    "from scipy import stats\n",
    "import math\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate(df, index_list, col):\n",
    "    count = len(index_list)\n",
    "    \n",
    "    before_index = index_list[0] - 1\n",
    "    before_val = df.loc[before_index,col]\n",
    "    \n",
    "    after_index = index_list[len(index_list)-1] + 1\n",
    "    after_val = df.loc[after_index,col]\n",
    "    \n",
    "    inc_amount = (after_val - before_val) / (count + 1)\n",
    "    \n",
    "    for i in range(count):\n",
    "        update_index = index_list[i]\n",
    "        update_val = df.loc[update_index-1,col] + inc_amount\n",
    "        df.loc[update_index,col] = update_val\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"data/Protocol/\"\n",
    "files_path = data_folder + \"subject*.dat\"\n",
    "\n",
    "# ====================\n",
    "#files_path = data_folder + \"subject101.dat\"\n",
    "# ====================\n",
    "\n",
    "df_main = pd.DataFrame(columns=['exp_id','label_id', \\\n",
    "                                'hand_acc0','hand_acc1','hand_acc2','hand_gyro0','hand_gyro1','hand_gyro2', \\\n",
    "                                'chest_acc0','chest_acc1','chest_acc2','chest_gyro0','chest_gyro1','chest_gyro2', \\\n",
    "                                'ankle_acc0','ankle_acc1','ankle_acc2','ankle_gyro0','ankle_gyro1','ankle_gyro2' \\\n",
    "                               ])\n",
    "\n",
    "files = glob.glob(files_path)\n",
    "for file in files:\n",
    "    df_exp = pd.read_csv(file, header=None, delimiter=r\"\\s+\")\n",
    "    df_exp_filtered = df_exp.filter([1, 4, 5, 6, 10, 11, 12, 21, 22, 23, 27, 28, 29, 38, 39, 40, 44, 45, 46])\n",
    "    df_exp_filtered.columns = ['label_id', \\\n",
    "                               'hand_acc0','hand_acc1','hand_acc2','hand_gyro0','hand_gyro1','hand_gyro2', \\\n",
    "                               'chest_acc0','chest_acc1','chest_acc2','chest_gyro0','chest_gyro1','chest_gyro2', \\\n",
    "                               'ankle_acc0','ankle_acc1','ankle_acc2','ankle_gyro0','ankle_gyro1','ankle_gyro2' \\\n",
    "                              ]\n",
    "    \n",
    "    exp_id = int(file[23])\n",
    "    df_exp_filtered['exp_id'] = exp_id\n",
    "    \n",
    "    if exp_id==9:\n",
    "        continue\n",
    "    \n",
    "    cols=['exp_id','label_id', \\\n",
    "          'hand_acc0','hand_acc1','hand_acc2','hand_gyro0','hand_gyro1','hand_gyro2', \\\n",
    "          'chest_acc0','chest_acc1','chest_acc2','chest_gyro0','chest_gyro1','chest_gyro2', \\\n",
    "          'ankle_acc0','ankle_acc1','ankle_acc2','ankle_gyro0','ankle_gyro1','ankle_gyro2' \\\n",
    "         ]\n",
    "    df_exp_filtered = df_exp_filtered[cols]\n",
    "    \n",
    "    total_rows = len(df_exp_filtered)\n",
    "    interpol_cols = ['hand_acc0','hand_acc1','hand_acc2','hand_gyro0','hand_gyro1','hand_gyro2', \\\n",
    "                     'chest_acc0','chest_acc1','chest_acc2','chest_gyro0','chest_gyro1','chest_gyro2', \\\n",
    "                     'ankle_acc0','ankle_acc1','ankle_acc2','ankle_gyro0','ankle_gyro1','ankle_gyro2' \\\n",
    "                    ]\n",
    "    for col in interpol_cols:\n",
    "        index = 0\n",
    "        while index < total_rows:\n",
    "            if math.isnan(df_exp_filtered.loc[index,col]):\n",
    "                index_list = [index]\n",
    "                nan_index = index + 1\n",
    "                while (True):\n",
    "                    if math.isnan(df_exp_filtered.loc[nan_index,col]):\n",
    "                        index_list.append(nan_index)\n",
    "                        nan_index += 1\n",
    "                    else:\n",
    "                        break\n",
    "                df_exp_filtered = interpolate(df_exp_filtered, index_list, col)\n",
    "            index += 1\n",
    "    \n",
    "    df_main = df_main.append(df_exp_filtered, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test interpolate for exp 1\n",
    "# df_exp_filtered[19190:19199]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 512\n",
    "window_move_size = 100 #window_size // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(df_OVA):\n",
    "\n",
    "    curr_index = 0\n",
    "    act_start_index = 0\n",
    "    act_end_index = 0\n",
    "\n",
    "    df_OVA_trimmed = pd.DataFrame(columns=['exp_id','label_id', \\\n",
    "                                           'hand_acc0','hand_acc1','hand_acc2','hand_gyro0','hand_gyro1','hand_gyro2', \\\n",
    "                                           'chest_acc0','chest_acc1','chest_acc2','chest_gyro0','chest_gyro1','chest_gyro2', \\\n",
    "                                           'ankle_acc0','ankle_acc1','ankle_acc2','ankle_gyro0','ankle_gyro1','ankle_gyro2' \\\n",
    "                                          ])\n",
    "\n",
    "    while (True):\n",
    "        curr_act_id = df_OVA.loc[act_start_index, 'label_id']\n",
    "    \n",
    "        curr_index = act_start_index + 1\n",
    "        while (True):\n",
    "            act_id = df_OVA.loc[curr_index, 'label_id']\n",
    "            if (act_id != curr_act_id):\n",
    "                act_end_index = curr_index - 1\n",
    "                break\n",
    "            elif curr_index == (len(df_OVA) - 1):\n",
    "                act_end_index = curr_index\n",
    "                break\n",
    "            else:\n",
    "                curr_index += 1\n",
    "            \n",
    "        df_act_trimmed = df_OVA[act_start_index + 1000 : act_end_index - 1000]\n",
    "    \n",
    "        if len(df_act_trimmed) > 0:\n",
    "            df_OVA_trimmed = df_OVA_trimmed.append(df_act_trimmed, ignore_index = True)\n",
    "            #df_OVA_trimmed = df_OVA_trimmed.reset_index(drop=True)\n",
    "    \n",
    "        if curr_index >= (len(df_OVA) - 1):\n",
    "            break\n",
    "        else:\n",
    "            act_start_index = act_end_index + 1\n",
    "    \n",
    "    return df_OVA_trimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment(df_OVA):\n",
    "\n",
    "    segmeneted_activities = [ 'N/A',[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[] ]\n",
    "\n",
    "    for i in range(1 , 9):\n",
    "\n",
    "        df_exp = df_OVA.loc[df_OVA['exp_id'] == i]\n",
    "        df_exp = df_exp.reset_index(drop=True)\n",
    "\n",
    "        index = 0\n",
    "        continu = True\n",
    "        while (continu):\n",
    "\n",
    "            if index >= len(df_exp):\n",
    "                break\n",
    "\n",
    "            df_window = df_exp.loc[index:index+window_size-1]\n",
    "            if len(df_window) < window_size:\n",
    "                break\n",
    "\n",
    "            window_label_ids = set(df_window['label_id'].values)\n",
    "            if (len(window_label_ids) > 1) or \\\n",
    "               (len(window_label_ids)==1 and next(iter(window_label_ids))==0):\n",
    "                index = index + window_move_size\n",
    "                continue\n",
    "\n",
    "            na_window = np.array((df_window.loc[:,'hand_acc0':'ankle_gyro2']))\n",
    "            window_label_id = next(iter(window_label_ids))\n",
    "\n",
    "            segmeneted_activities[window_label_id].append(na_window)\n",
    "            index = index + window_move_size\n",
    "\n",
    "    for i in range(1,25):\n",
    "        segmeneted_activities[i] = np.array(segmeneted_activities[i])\n",
    "        \n",
    "    for i in range(1,25):\n",
    "        print (\"Act_id:\" , i , \" \" , segmeneted_activities[i].shape)\n",
    "        \n",
    "    return segmeneted_activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binary_X_and_Y_oversampled(act_id, segmeneted_activities):\n",
    "    \n",
    "    X , Y = get_binary_X_and_Y (act_id, segmeneted_activities)\n",
    "\n",
    "    total_datapoints = X.shape[0]\n",
    "    plus_datapoints = segmeneted_activities[act_id].shape[0]\n",
    "    alpha = (total_datapoints - plus_datapoints) / plus_datapoints\n",
    "    alpha = round(alpha, 1)\n",
    "    fraction = int(str(alpha)[-1])\n",
    "    alpha = int(alpha)\n",
    "    plus_class_counter = -1\n",
    "    \n",
    "    New_X = []\n",
    "    New_Y = []\n",
    "\n",
    "    for i in range(total_datapoints):\n",
    "        \n",
    "        if (Y[i]==1):\n",
    "            plus_class_counter += 1\n",
    "            for j in range(alpha):\n",
    "                New_X.append(X[i])\n",
    "                New_Y.append(Y[i])\n",
    "\n",
    "            if (plus_class_counter % 10) < fraction:\n",
    "                New_X.append(X[i])\n",
    "                New_Y.append(Y[i])\n",
    "                \n",
    "        else:\n",
    "            New_X.append(X[i])\n",
    "            New_Y.append(Y[i])\n",
    "\n",
    "    New_X = np.array(New_X)\n",
    "    New_Y = np.array(New_Y)\n",
    "    \n",
    "    return New_X , New_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binary_X_and_Y (act_id , segmeneted_activities):\n",
    "\n",
    "    X = np.concatenate((segmeneted_activities[1], segmeneted_activities[2]))\n",
    "    X = np.concatenate((           X            , segmeneted_activities[3]))\n",
    "    X = np.concatenate((           X            , segmeneted_activities[17]))\n",
    "    X = np.concatenate((           X            , segmeneted_activities[16]))\n",
    "    X = np.concatenate((           X            , segmeneted_activities[12]))\n",
    "    X = np.concatenate((           X            , segmeneted_activities[13]))\n",
    "    X = np.concatenate((           X            , segmeneted_activities[4]))\n",
    "    X = np.concatenate((           X            , segmeneted_activities[7]))\n",
    "    X = np.concatenate((           X            , segmeneted_activities[6]))\n",
    "    X = np.concatenate((           X            , segmeneted_activities[5]))\n",
    "    X = np.concatenate((           X            , segmeneted_activities[24]))\n",
    "\n",
    "    ys = ['N/A',None,None,None,None,None,None,None,None,None,None,None, \\\n",
    "          None,None,None,None,None,None,None,None,None,None,None,None,None]\n",
    "    for i in range(1,25):\n",
    "        size = segmeneted_activities[i].shape[0]\n",
    "        if act_id == i:\n",
    "            y = np.full (size , 1)\n",
    "        else:\n",
    "            y = np.full (size , 0)\n",
    "        ys[i] = y\n",
    "\n",
    "    Y = np.concatenate((ys[1], ys[2]))\n",
    "    Y = np.concatenate((  Y  , ys[3]))\n",
    "    Y = np.concatenate((  Y  , ys[17]))\n",
    "    Y = np.concatenate((  Y  , ys[16]))\n",
    "    Y = np.concatenate((  Y  , ys[12]))\n",
    "    Y = np.concatenate((  Y  , ys[13]))\n",
    "    Y = np.concatenate((  Y  , ys[4]))\n",
    "    Y = np.concatenate((  Y  , ys[7]))\n",
    "    Y = np.concatenate((  Y  , ys[6]))\n",
    "    Y = np.concatenate((  Y  , ys[5]))\n",
    "    Y = np.concatenate((  Y  , ys[24]))\n",
    "\n",
    "    return (X , Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model (data_input_shape):\n",
    "\n",
    "    LSTM_output_dim = 100\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    #model.add(LSTM(LSTM_output_dim, return_sequences=True, name='LSTM1', input_shape=data_input_shape))    \n",
    "    #model.add(LSTM(LSTM_output_dim, return_sequences=True, name='LSTM2'))\n",
    "    #model.add(LSTM(LSTM_output_dim, return_sequences=False, name='LSTM3'))\n",
    "    \n",
    "    model.add(LSTM(LSTM_output_dim, return_sequences=False, name='LSTM1', input_shape=data_input_shape))\n",
    "    \n",
    "    model.add(Dense(15, activation='sigmoid',name='Hidden_Layer'))\n",
    "    \n",
    "    #model.add(Dense(3, activation='softmax', name='Softmax_layer'))\n",
    "    model.add(Dense(1, activation='sigmoid',name='Dense_out'))\n",
    "    \n",
    "    #model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_binary_classifier(act_id, segmeneted_activities):\n",
    "    #(X , Y) = get_binary_X_and_Y (act_id , segmeneted_activities)\n",
    "    (X , Y) = get_binary_X_and_Y_oversampled (act_id , segmeneted_activities)\n",
    "    \n",
    "    X , Y = shuffle(X , Y)\n",
    "\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.25)\n",
    "    X_train,X_valid,y_train,y_valid=train_test_split(X_train,y_train,test_size=0.333)\n",
    "\n",
    "    data_input_shape = X.shape[1:3]\n",
    "    model = create_model(data_input_shape)\n",
    "    #print (model.summary()  , \"\\n\")\n",
    "\n",
    "    patience = 5\n",
    "    callbacks=[EarlyStopping(monitor='val_loss',patience=patience,verbose=1)]\n",
    "    history = model.fit(X_train,y_train,\n",
    "                        validation_data=[X_valid,y_valid],\n",
    "                        epochs=20, \n",
    "                        batch_size=100,\n",
    "                        verbose=2\n",
    "                        ,callbacks=callbacks\n",
    "                       )\n",
    "\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('\\nTest loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    print ()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df_OVA):\n",
    "    df_OVA = trim(df_OVA)\n",
    "    \n",
    "    segmeneted_activities = segment(df_OVA)\n",
    "    \n",
    "    #training binary classifier for activity 1 (Lying)\n",
    "    print ()\n",
    "    print (\"Training activity 1 ...\")\n",
    "    act_id = 1\n",
    "    model_1 = train_binary_classifier(act_id, segmeneted_activities)\n",
    "    #model_1.save('model512_1.h5')\n",
    "    \n",
    "    #training binary classifier for activity 2 (Sitting)\n",
    "    print (\"Training activity 2 ...\")\n",
    "    act_id = 2\n",
    "    model_2 = train_binary_classifier(act_id, segmeneted_activities)\n",
    "    #model_2.save('model512_2.h5')\n",
    "\n",
    "    #training binary classifier for activity 3 (Standing)\n",
    "    print (\"Training activity 3 ...\")\n",
    "    act_id = 3\n",
    "    model_3 = train_binary_classifier(act_id, segmeneted_activities)\n",
    "    #model_3.save('model512_3.h5')\n",
    "    \n",
    "    #training binary classifier for activity 17 (Ironing)\n",
    "    print (\"Training activity 17 ...\")\n",
    "    act_id = 17\n",
    "    model_17 = train_binary_classifier(act_id, segmeneted_activities)\n",
    "    #model_17.save('model512_17.h5')\n",
    "    \n",
    "    #training binary classifier for activity 16 (Vacuum Cleaning)\n",
    "    print (\"Training activity 16 ...\")\n",
    "    act_id = 16\n",
    "    model_16 = train_binary_classifier(act_id, segmeneted_activities)\n",
    "    #model_16.save('model512_16.h5')\n",
    "    \n",
    "    #training binary classifier for activity 12 (Ascending Stairs)\n",
    "    print (\"Training activity 12 ...\")\n",
    "    act_id = 12\n",
    "    model_12 = train_binary_classifier(act_id, segmeneted_activities)\n",
    "    #model_12.save('model512_12.h5')\n",
    "    \n",
    "    #training binary classifier for activity 13 (Descending Stairs)\n",
    "    print (\"Training activity 13 ...\")\n",
    "    act_id = 13\n",
    "    model_13 = train_binary_classifier(act_id, segmeneted_activities)\n",
    "    #model_13.save('model512_13.h5')\n",
    "    \n",
    "    #training binary classifier for activity 4 (Walking)\n",
    "    print (\"Training activity 4 ...\")\n",
    "    act_id = 4\n",
    "    model_4 = train_binary_classifier(act_id, segmeneted_activities)\n",
    "    #model_4.save('model512_4.h5')\n",
    "    \n",
    "    #training binary classifier for activity 7 (Nordic Walking)\n",
    "    print (\"Training activity 7 ...\")\n",
    "    act_id = 7\n",
    "    model_7 = train_binary_classifier(act_id, segmeneted_activities)\n",
    "    #model_7.save('model512_7.h5')\n",
    "    \n",
    "    #training binary classifier for activity 6 (Cycling)\n",
    "    print (\"Training activity 6 ...\")\n",
    "    act_id = 6\n",
    "    model_6 = train_binary_classifier(act_id, segmeneted_activities)\n",
    "    #model_6.save('model512_6.h5')\n",
    "    \n",
    "    #training binary classifier for activity 5 (Running)\n",
    "    print (\"Training activity 5 ...\")\n",
    "    act_id = 5\n",
    "    model_5 = train_binary_classifier(act_id, segmeneted_activities)\n",
    "    #model_5.save('model512_5.h5')\n",
    "    \n",
    "    #training binary classifier for activity 24 (Rope Jumping)\n",
    "    print (\"Training activity 24 ...\")\n",
    "    act_id = 24\n",
    "    model_24 = train_binary_classifier(act_id, segmeneted_activities)\n",
    "    #model_24.save('model512_24.h5')\n",
    "    \n",
    "    models = [None,None,None,None,None,None,None,None,None,None,None,None, \\\n",
    "              None,None,None,None,None,None,None,None,None,None,None,None,None]\n",
    "    models[1] = model_1\n",
    "    models[2] = model_2\n",
    "    models[3] = model_3\n",
    "    models[17] = model_17\n",
    "    models[16] = model_16\n",
    "    models[12] = model_12\n",
    "    models[13] = model_13\n",
    "    models[4] = model_4\n",
    "    models[7] = model_7\n",
    "    models[6] = model_6\n",
    "    models[5] = model_5\n",
    "    models[24] = model_24\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "# model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_predict, models):\n",
    "\n",
    "    X_predict = np.reshape(X_predict , (1,X_predict.shape[0],X_predict.shape[1]))\n",
    "\n",
    "    scores = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "    for i in range(24):\n",
    "        model = models[i+1]\n",
    "        if (model is not None):\n",
    "            pred_probs = model.predict_proba(X_predict)\n",
    "            scores[i] = pred_probs[0][0]\n",
    "\n",
    "    threshold = 0.5\n",
    "    if max(scores) < threshold:\n",
    "        label_id = 0\n",
    "    else:\n",
    "        label_id = scores.index(max(scores)) + 1\n",
    "    \n",
    "    return label_id, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(df_continuous , models):\n",
    "\n",
    "    # =================\n",
    "    #df_continuous2 = df_continuous.loc[df_continuous['exp_id'] == 7]\n",
    "    df_continuous2 = df_continuous\n",
    "    # =================\n",
    "\n",
    "    index = 0\n",
    "    continu = True\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "    while (continu):\n",
    "\n",
    "        if index >= len(df_continuous2):\n",
    "            break\n",
    "\n",
    "        df_window = df_continuous2.loc[index:index+window_size-1]\n",
    "        if len(df_window) < window_size:\n",
    "            break\n",
    "\n",
    "        mode_win_labels = stats.mode(df_window['label_id'].values)\n",
    "        window_label_id = mode_win_labels[0][0]\n",
    "\n",
    "        if window_label_id == 0:\n",
    "            print (\"Window Label: 0\")\n",
    "            index = index + window_move_size\n",
    "            continue\n",
    "\n",
    "        na_window = np.array((df_window.loc[:,'hand_acc0':'ankle_gyro2']))\n",
    "        pred_label_id, _ = predict(na_window, models)\n",
    "\n",
    "        print (\"Window Label: \" + str(window_label_id) + \"  Predicted Label: \" + str(pred_label_id))\n",
    "        \n",
    "        total_preds += 1\n",
    "\n",
    "        if (pred_label_id == window_label_id):\n",
    "            correct_preds += 1\n",
    "\n",
    "        index = index + window_move_size\n",
    "            \n",
    "    accu = correct_preds/total_preds\n",
    "    print (\"\\nContinuous Accuracy: \" + str(accu))\n",
    "    return accu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cao et al Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_u(df_OVA):\n",
    "\n",
    "    run_lengths = []\n",
    "    current_label = 0\n",
    "    run_length = 1\n",
    "\n",
    "    for i in range(1 , len(df_OVA)):\n",
    "    \n",
    "        label = df_OVA.loc[i , 'label_id']\n",
    "    \n",
    "        if current_label == label:\n",
    "            run_length += 1\n",
    "            continue\n",
    "        else:\n",
    "            if current_label != 0:\n",
    "                run_lengths.append(run_length)\n",
    "            run_length = 1\n",
    "            current_label = label\n",
    "            continue\n",
    "        \n",
    "    run_lengths = np.array(run_lengths)\n",
    "    run_lengths_sorted = np.sort(run_lengths)\n",
    "    p = 1. * np.arange(len(run_lengths)) / (len(run_lengths) - 1)\n",
    "\n",
    "    #import matplotlib.pyplot as plt\n",
    "    #plt.figure()\n",
    "    #plt.plot(run_lengths_sorted, p)\n",
    "    #plt.title('cumulative distribution function (CDF) of all run lengths')\n",
    "    #plt.ylabel('p')\n",
    "    #plt.xlabel('run length')\n",
    "    #plt.show()\n",
    "\n",
    "    thr = 0.03\n",
    "    for i in range(p.shape[0]):\n",
    "        if p[i] >= thr:\n",
    "            break\n",
    "\n",
    "    idx = i-1\n",
    "    u = run_lengths_sorted[idx]\n",
    "    u = round((u - window_size) / (2.0 * window_move_size))\n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_with_cao_smoothing_3 (df_continuous , models):\n",
    "\n",
    "    df_continuous2 = df_continuous\n",
    "\n",
    "    index = 0\n",
    "    continu = True\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "    l = []\n",
    "    w = []\n",
    "    while (continu):\n",
    "        \n",
    "        if index >= len(df_continuous2):\n",
    "            break\n",
    "        \n",
    "        df_window = df_continuous2.loc[index:index+window_size-1]\n",
    "        if len(df_window) < window_size:\n",
    "            break\n",
    "        \n",
    "        mode_win_labels = stats.mode(df_window['label_id'].values)\n",
    "        window_label_id = mode_win_labels[0][0]\n",
    "    \n",
    "        if window_label_id == 0:\n",
    "            l.append(0)\n",
    "            w.append(0)\n",
    "        \n",
    "        else:    \n",
    "            na_window = np.array((df_window.loc[:,'hand_acc0':'ankle_gyro2']))\n",
    "            pred_label_id, _ = predict(na_window, models)\n",
    "            l.append(pred_label_id)\n",
    "            w.append(window_label_id)\n",
    "    \n",
    "        i = len(l)\n",
    "        if i == 2:\n",
    "            if w[0] == 0:\n",
    "                print (\"Window Label: 0\")\n",
    "                index = index + window_move_size\n",
    "                continue\n",
    "            smoothed_pred_label_id = l[0]\n",
    "            total_preds += 1\n",
    "            if (smoothed_pred_label_id == w[0]):\n",
    "                correct_preds += 1\n",
    "        \n",
    "        elif i > 2:\n",
    "        \n",
    "            if w[i-2]==0:\n",
    "                print (\"Window Label: 0\")\n",
    "                index = index + window_move_size\n",
    "                continue\n",
    "            \n",
    "            elif w[i-1]==0:\n",
    "                smoothed_pred_label_id = l[i-2]\n",
    "            \n",
    "            elif w[i-3]==0:\n",
    "                smoothed_pred_label_id = l[i-2]\n",
    "            \n",
    "            else:\n",
    "                pred_seg = [ l[i-3] , l[i-2] , l[i-1] ]\n",
    "                mode = stats.mode(pred_seg)\n",
    "                if mode[1][0] > 1:\n",
    "                    smoothed_pred_label_id = mode[0][0]\n",
    "                else:\n",
    "                    smoothed_pred_label_id = l[i-2]\n",
    "            \n",
    "            print (\"Window Label: \" + str(w[i-2]) + \"  Smoothed Predicted Label: \" + str(smoothed_pred_label_id))\n",
    "      \n",
    "            total_preds += 1\n",
    "        \n",
    "            if (smoothed_pred_label_id == w[i-2]):        \n",
    "                correct_preds += 1\n",
    "        \n",
    "        index = index + window_move_size\n",
    "            \n",
    "    accu = correct_preds/total_preds\n",
    "    print (\"\\nContinuous Accuracy: \" + str(accu))\n",
    "    return accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_with_cao_smoothing_5 (df_continuous , models):\n",
    "\n",
    "    df_continuous2 = df_continuous\n",
    "    \n",
    "    index = 0\n",
    "    continu = True\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "    l = []\n",
    "    w = []\n",
    "    while (continu):\n",
    "        \n",
    "        if index >= len(df_continuous2):\n",
    "            break\n",
    "        \n",
    "        df_window = df_continuous2.loc[index:index+window_size-1]\n",
    "        if len(df_window) < window_size:\n",
    "            break\n",
    "        \n",
    "        mode_win_labels = stats.mode(df_window['label_id'].values)\n",
    "        window_label_id = mode_win_labels[0][0]\n",
    "    \n",
    "        if window_label_id == 0:\n",
    "            l.append(0)\n",
    "            w.append(0)\n",
    "        \n",
    "        else:    \n",
    "            na_window = np.array((df_window.loc[:,'hand_acc0':'ankle_gyro2']))\n",
    "            pred_label_id, _ = predict(na_window, models)\n",
    "            l.append(pred_label_id)\n",
    "            w.append(window_label_id)\n",
    "    \n",
    "        i = len(l)\n",
    "        if i==3 or i==4:\n",
    "            if w[i-3]==0:\n",
    "                print (\"Window Label: 0\")\n",
    "                index = index + window_move_size\n",
    "                continue\n",
    "            smoothed_pred_label_id = l[i-3]\n",
    "            total_preds += 1\n",
    "            if (smoothed_pred_label_id == w[i-3]):\n",
    "                correct_preds += 1\n",
    "        \n",
    "        elif i >= 5:\n",
    "        \n",
    "            if w[i-3]==0:\n",
    "                print (\"Window Label: 0\")\n",
    "                index = index + window_move_size\n",
    "                continue\n",
    "            \n",
    "            elif w[i-1]==0 or w[i-2]==0 or w[i-4]==0 or w[i-5]==0:\n",
    "                smoothed_pred_label_id = l[i-3]\n",
    "            \n",
    "            else:\n",
    "                pred_seg = [ l[i-5] , l[i-4] , l[i-3] , l[i-2] , l[i-1] ]\n",
    "                mode = stats.mode(pred_seg)\n",
    "                if mode[1][0] > 1:\n",
    "                    smoothed_pred_label_id = mode[0][0]\n",
    "                else:\n",
    "                    smoothed_pred_label_id = l[i-3]\n",
    "            \n",
    "            print (\"Window Label: \" + str(w[i-3]) + \"  Smoothed Predicted Label: \" + str(smoothed_pred_label_id))\n",
    "      \n",
    "            total_preds += 1\n",
    "        \n",
    "            if (smoothed_pred_label_id == w[i-3]):        \n",
    "                correct_preds += 1\n",
    "        \n",
    "        index = index + window_move_size\n",
    "            \n",
    "    accu = correct_preds/total_preds\n",
    "    print (\"\\nContinuous Accuracy: \" + str(accu))\n",
    "    return accu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Krishnan et al Smoothing\n",
    "\n",
    "delta_t = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(x):\n",
    "    \n",
    "    result = (1. / (math.sqrt(2*math.pi))) * np.exp(-0.5 * x * x)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_window_feature_vector(X_predict , intermediate_layer_model):\n",
    "    \n",
    "    intermediate_output = intermediate_layer_model.predict(X_predict)\n",
    "    intermediate_output = np.reshape(intermediate_output, (intermediate_output.shape[1]))\n",
    "    \n",
    "    return intermediate_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euc_dist (f1 , f2):\n",
    "    \n",
    "    dist = np.linalg.norm(f2-f1)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h(f1 , f2):\n",
    "\n",
    "    alpha = 1\n",
    "    result = np.exp(-alpha * euc_dist(f1 , f2))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predict_vector(na_window, models, intermediate_layer_models):\n",
    "    \n",
    "    X_predict = na_window\n",
    "    X_predict = np.reshape(X_predict , (1,X_predict.shape[0],X_predict.shape[1]))\n",
    "\n",
    "    scores = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    f = [None, None, None, None, None, None, None, None, None, None, None, None, \\\n",
    "         None, None, None, None, None, None, None, None, None, None, None, None]\n",
    "    \n",
    "    for i in range(24):\n",
    "        model = models[i+1]\n",
    "        if (model is not None):\n",
    "            pred_probs = model.predict_proba(X_predict)\n",
    "            scores[i] = pred_probs[0][0]\n",
    "\n",
    "            f[i] = get_window_feature_vector(X_predict , intermediate_layer_models[i+1])\n",
    "    \n",
    "    return scores , f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_with_Krishnan_smoothing_delta3(df_continuous , models):\n",
    "\n",
    "    intermediate_layer_model_1 = Model(inputs=models[1].input, outputs=models[1].get_layer(\"LSTM1\").output)\n",
    "    intermediate_layer_model_2 = Model(inputs=models[2].input, outputs=models[2].get_layer(\"LSTM1\").output)\n",
    "    intermediate_layer_model_3 = Model(inputs=models[3].input, outputs=models[3].get_layer(\"LSTM1\").output)\n",
    "    intermediate_layer_model_17 = Model(inputs=models[17].input, outputs=models[17].get_layer(\"LSTM1\").output)\n",
    "    intermediate_layer_model_16 = Model(inputs=models[16].input, outputs=models[16].get_layer(\"LSTM1\").output)\n",
    "    intermediate_layer_model_12 = Model(inputs=models[12].input, outputs=models[12].get_layer(\"LSTM1\").output)\n",
    "    intermediate_layer_model_13 = Model(inputs=models[13].input, outputs=models[13].get_layer(\"LSTM1\").output)\n",
    "    intermediate_layer_model_4 = Model(inputs=models[4].input, outputs=models[4].get_layer(\"LSTM1\").output)\n",
    "    intermediate_layer_model_7 = Model(inputs=models[7].input, outputs=models[7].get_layer(\"LSTM1\").output)\n",
    "    intermediate_layer_model_6 = Model(inputs=models[6].input, outputs=models[6].get_layer(\"LSTM1\").output)\n",
    "    intermediate_layer_model_5 = Model(inputs=models[5].input, outputs=models[5].get_layer(\"LSTM1\").output)\n",
    "    intermediate_layer_model_24 = Model(inputs=models[24].input, outputs=models[24].get_layer(\"LSTM1\").output)\n",
    "\n",
    "    intermediate_layer_models = [None,None,None,None,None,None,None,None,None,None,None,None, \\\n",
    "                                 None,None,None,None,None,None,None,None,None,None,None,None,None]\n",
    "    intermediate_layer_models[1] = intermediate_layer_model_1\n",
    "    intermediate_layer_models[2] = intermediate_layer_model_2\n",
    "    intermediate_layer_models[3] = intermediate_layer_model_3\n",
    "    intermediate_layer_models[17] = intermediate_layer_model_17\n",
    "    intermediate_layer_models[16] = intermediate_layer_model_16\n",
    "    intermediate_layer_models[12] = intermediate_layer_model_12\n",
    "    intermediate_layer_models[13] = intermediate_layer_model_13\n",
    "    intermediate_layer_models[4] = intermediate_layer_model_4\n",
    "    intermediate_layer_models[7] = intermediate_layer_model_7\n",
    "    intermediate_layer_models[6] = intermediate_layer_model_6\n",
    "    intermediate_layer_models[5] = intermediate_layer_model_5\n",
    "    intermediate_layer_models[24] = intermediate_layer_model_24\n",
    "    \n",
    "    df_continuous2 = df_continuous\n",
    "\n",
    "    index = 0\n",
    "    continu = True\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "\n",
    "    num_of_classes = 24\n",
    "    P = [[] , [] , [] , [] , [] , [] , [] , [] , [] , [] , [] , [] , \\\n",
    "         [] , [] , [] , [] , [] , [] , [] , [] , [] , [] , [] , []]\n",
    "    fs = [[] , [] , [] , [] , [] , [] , [] , [] , [] , [] , [] , [] , \\\n",
    "         [] , [] , [] , [] , [] , [] , [] , [] , [] , [] , [] , []]\n",
    "    delta_t = 3\n",
    "\n",
    "    while (continu):\n",
    "        \n",
    "        if index >= len(df_continuous2):\n",
    "            break\n",
    "        \n",
    "        df_window = df_continuous2.loc[index:index+window_size-1]\n",
    "        if len(df_window) < window_size:\n",
    "            break\n",
    "        \n",
    "        mode_win_labels = stats.mode(df_window['label_id'].values)\n",
    "        window_label_id = mode_win_labels[0][0]\n",
    "    \n",
    "        if window_label_id == 0:\n",
    "            P = [[] , [] , [] , [] , [] , [] , [] , [] , [] , [] , [] , [] , \\\n",
    "                 [] , [] , [] , [] , [] , [] , [] , [] , [] , [] , [] , []]\n",
    "            fs = [[] , [] , [] , [] , [] , [] , [] , [] , [] , [] , [] , [] , \\\n",
    "                  [] , [] , [] , [] , [] , [] , [] , [] , [] , [] , [] , []]\n",
    "            print (\"Window Label: 0\")\n",
    "            index = index + window_move_size\n",
    "            continue\n",
    "        \n",
    "        na_window = np.array((df_window.loc[:,'hand_acc0':'ankle_gyro2']))\n",
    "        p , f = get_predict_vector(na_window , models, intermediate_layer_models)\n",
    "    \n",
    "        t = len(P[0])\n",
    "    \n",
    "        if t < (delta_t):\n",
    "            for i in range(num_of_classes):\n",
    "                P[i].append(p[i])\n",
    "                fs[i].append(f[i])\n",
    "            \n",
    "        else:\n",
    "            for i in range(num_of_classes):\n",
    "                \n",
    "                if (i+1) in [1,2,3,17,16,12,13,4,7,6,5,24]:\n",
    "            \n",
    "                    fs[i].append(f[i])\n",
    "            \n",
    "                    s1 = 0\n",
    "                    for j in range(1 , delta_t+1):\n",
    "                        s1 += g(j) * h(fs[i][t-j] , fs[i][t]) * P[i][t-j]\n",
    "            \n",
    "                    s2 = 0\n",
    "                    for j in range(1 , delta_t+1):\n",
    "                        s2 += g(j) * h(fs[i][t-j] , fs[i][t])\n",
    "            \n",
    "                    P[i].append( (p[i] + s1) / (s2 + 1) )\n",
    "                \n",
    "                else:\n",
    "                    P[i].append(0)\n",
    "    \n",
    "    \n",
    "        current_P = []\n",
    "        for i in range(num_of_classes):\n",
    "            current_P.append ( P[i][t] )\n",
    "    \n",
    "        threshold = 0.5\n",
    "        if max(current_P) < threshold:\n",
    "            pred_label_id = 0\n",
    "        else:\n",
    "            pred_label_id = current_P.index(max(current_P)) + 1\n",
    "    \n",
    "        print (\"Window Label: \" + str(window_label_id) + \"  Smoothed Predicted Label: \" + str(pred_label_id))\n",
    "    \n",
    "        total_preds += 1\n",
    "        \n",
    "        if (pred_label_id == window_label_id):\n",
    "            correct_preds += 1\n",
    "        \n",
    "        index = index + window_move_size\n",
    "            \n",
    "    accu = correct_preds/total_preds\n",
    "    print (\"\\nContinuous Accuracy: \" + str(accu))\n",
    "    return accu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Simple Voting Scheme\n",
    "\n",
    "N = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_with_simple_voting_smoothing(df_continuous , models):\n",
    "\n",
    "    df_continuous2 = df_continuous\n",
    "\n",
    "    index = 0\n",
    "    continu = True\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "\n",
    "    N = 3\n",
    "    l = []\n",
    "\n",
    "    while (continu):\n",
    "        \n",
    "        if index >= len(df_continuous2):\n",
    "            break\n",
    "        \n",
    "        df_window = df_continuous2.loc[index:index+window_size-1]\n",
    "        if len(df_window) < window_size:\n",
    "            break\n",
    "        \n",
    "        mode_win_labels = stats.mode(df_window['label_id'].values)\n",
    "        window_label_id = mode_win_labels[0][0]\n",
    "    \n",
    "        if window_label_id == 0:\n",
    "            l = []\n",
    "            print (\"Window Label: 0\")\n",
    "            index = index + window_move_size\n",
    "            continue\n",
    "        \n",
    "        na_window = np.array((df_window.loc[:,'hand_acc0':'ankle_gyro2']))\n",
    "        pred_label_id, _ = predict(na_window, models)\n",
    "        l.append(pred_label_id)\n",
    "\n",
    "        t = len(l)\n",
    "    \n",
    "        if t < N:\n",
    "            smoothed_pred_label_id = pred_label_id\n",
    "            \n",
    "        else:\n",
    "            voting_list = []\n",
    "            for i in range(N):\n",
    "                voting_list.append( l[t-i-1] )\n",
    "        \n",
    "            mode = stats.mode(voting_list)\n",
    "        \n",
    "            if mode[1][0] > 1:\n",
    "                smoothed_pred_label_id = mode[0][0]\n",
    "            else:\n",
    "                smoothed_pred_label_id = pred_label_id\n",
    "\n",
    "    \n",
    "        print (\"Window Label: \" + str(window_label_id) + \"  Smoothed Predicted Label: \" + str(smoothed_pred_label_id))\n",
    "    \n",
    "        total_preds += 1\n",
    "        \n",
    "        if (smoothed_pred_label_id == window_label_id):        \n",
    "            correct_preds += 1\n",
    "        \n",
    "        index = index + window_move_size\n",
    "            \n",
    "    accu = correct_preds/total_preds\n",
    "    print (\"\\nContinuous Accuracy: \" + str(accu))\n",
    "    return accu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exponentially Weighted Voting\n",
    "\n",
    "alpha = 0.05, 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_with_EWV_smoothing (df_continuous , models, alpha):\n",
    "\n",
    "    df_continuous2 = df_continuous\n",
    "\n",
    "    index = 0\n",
    "    continu = True\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "\n",
    "    num_of_classes = 25\n",
    "    w = [ [] , [] , [] , [] , [] , [] , [] , [] , [] , [] , [] , [] , \\\n",
    "          [] , [] , [] , [] , [] , [] , [] , [] , [] , [] , [] , [] , [] ]\n",
    "\n",
    "    while (continu):\n",
    "        \n",
    "        if index >= len(df_continuous2):\n",
    "            break\n",
    "        \n",
    "        df_window = df_continuous2.loc[index:index+window_size-1]\n",
    "        if len(df_window) < window_size:\n",
    "            break\n",
    "        \n",
    "        mode_win_labels = stats.mode(df_window['label_id'].values)\n",
    "        window_label_id = mode_win_labels[0][0]\n",
    "    \n",
    "        if window_label_id == 0:\n",
    "            w = [ [] , [] , [] , [] , [] , [] , [] , [] , [] , [] , [] , [] , \\\n",
    "                  [] , [] , [] , [] , [] , [] , [] , [] , [] , [] , [] , [] , [] ]\n",
    "            print (\"Window Label: 0\")\n",
    "            index = index + window_move_size\n",
    "            continue\n",
    "        \n",
    "        na_window = np.array((df_window.loc[:,'hand_acc0':'ankle_gyro2']))\n",
    "        pred_label_id, _ = predict(na_window, models)\n",
    "\n",
    "        t = len(w[0])\n",
    "    \n",
    "        if t == 0:\n",
    "            smoothed_pred_label_id = pred_label_id\n",
    "            for i in range(num_of_classes):\n",
    "                if i==pred_label_id:\n",
    "                    w[i].append(alpha)\n",
    "                else:\n",
    "                    w[i].append(0)\n",
    "            \n",
    "        else:\n",
    "            current_ws = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "            for i in range(num_of_classes):\n",
    "            \n",
    "                if i == pred_label_id:\n",
    "                    c = 1\n",
    "                else:\n",
    "                    c = 0\n",
    "                weight = w[i][t-1] + alpha * ( c - w[i][t-1])\n",
    "                w[i].append(weight)\n",
    "                current_ws[i] = weight\n",
    "        \n",
    "            smoothed_pred_label_id = current_ws.index(max(current_ws))\n",
    "\n",
    "    \n",
    "        print (\"Window Label: \" + str(window_label_id) + \"  Smoothed Predicted Label: \" + str(smoothed_pred_label_id))\n",
    "    \n",
    "        total_preds += 1\n",
    "        \n",
    "        if (smoothed_pred_label_id == window_label_id):        \n",
    "            correct_preds += 1\n",
    "        \n",
    "        index = index + window_move_size\n",
    "            \n",
    "    accu = correct_preds/total_preds\n",
    "    print (\"\\nContinuous Accuracy: \" + str(accu))\n",
    "    return accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_accu = [0,0,0,0,0,0,0,0]\n",
    "folds_cao_3_accu = [0,0,0,0,0,0,0,0]\n",
    "folds_cao_5_accu = [0,0,0,0,0,0,0,0]\n",
    "folds_krishnan_accu = [0,0,0,0,0,0,0,0]\n",
    "folds_simple_voting_accu = [0,0,0,0,0,0,0,0]\n",
    "folds_EWV_alpha_5_accu = [0,0,0,0,0,0,0,0]\n",
    "folds_EWV_alpha_25_accu = [0,0,0,0,0,0,0,0]\n",
    "#folds_EWV_alpha_95_accu = [0,0,0,0,0,0,0,0]\n",
    "\n",
    "for i in range(1,9):\n",
    "    split_exp_id = i\n",
    "    df_continuous = df_main.loc[df_main['exp_id'] == split_exp_id]\n",
    "    df_continuous = df_continuous.reset_index(drop=True)\n",
    "\n",
    "    df_OVA = df_main.loc[df_main['exp_id'] != split_exp_id]\n",
    "    df_OVA = df_OVA.reset_index(drop=True)\n",
    "\n",
    "    print (\"fold\" , i , \"Training:\")\n",
    "    print (\"len of df_main:\" , str(len(df_main)))\n",
    "    print (\"len of df_continuous:\" , str(len(df_continuous)))\n",
    "    print (\"len of df_OVA:\" , str(len(df_OVA)))\n",
    "    print ()\n",
    "    \n",
    "    models = train(df_OVA)\n",
    "    \n",
    "    print (\"\\nfold\" , i , \"Testing:\")\n",
    "    accu = test(df_continuous, models)\n",
    "    folds_accu[i-1] = accu\n",
    "    \n",
    "    print (\"\\nCao et al Smoothing (length=3):\")\n",
    "    cao_3_accu = test_with_cao_smoothing_3 (df_continuous , models)\n",
    "    folds_cao_3_accu[i-1] = cao_3_accu\n",
    "    \n",
    "    print (\"\\nCao et al Smoothing (length=5):\")\n",
    "    cao_5_accu = test_with_cao_smoothing_5 (df_continuous , models)\n",
    "    folds_cao_5_accu[i-1] = cao_5_accu\n",
    "    \n",
    "    print (\"\\nKrishnan et al Smoothing (delta_t=3):\")\n",
    "    krishnan_accu = test_with_Krishnan_smoothing_delta3(df_continuous , models)\n",
    "    folds_krishnan_accu[i-1] = krishnan_accu\n",
    "    \n",
    "    print (\"\\nSimple Voting Scheme Smoothing:\")\n",
    "    simple_voting_accu = test_with_simple_voting_smoothing(df_continuous , models)\n",
    "    folds_simple_voting_accu[i-1] = simple_voting_accu\n",
    "    \n",
    "    print (\"\\nExponentially Weighted Voting (EWV) Smoothing (alpha=0.05):\")\n",
    "    EWV_alpha_5_accu = test_with_EWV_smoothing (df_continuous , models, 0.05)\n",
    "    folds_EWV_alpha_5_accu[i-1] = EWV_alpha_5_accu\n",
    "\n",
    "    print (\"\\nExponentially Weighted Voting (EWV) Smoothing (alpha=0.25):\")\n",
    "    EWV_alpha_25_accu = test_with_EWV_smoothing (df_continuous , models, 0.25)\n",
    "    folds_EWV_alpha_25_accu[i-1] = EWV_alpha_25_accu\n",
    "\n",
    "    #print (\"\\nExponentially Weighted Voting (EWV) Smoothing (alpha=0.95):\")\n",
    "    #EWV_alpha_95_accu = test_with_EWV_smoothing (df_continuous , models, 0.95)\n",
    "    #folds_EWV_alpha_95_accu[i-1] = EWV_alpha_95_accu\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_folds (lst):\n",
    "    sum = 0\n",
    "    for i in range(len(lst)):\n",
    "        sum += lst[i]\n",
    "    \n",
    "    avg = sum / len(lst)\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_accu = get_avg_folds(folds_accu)\n",
    "print (\"\\nAverage Accuracy for all folds:\" , avg_accu)\n",
    "\n",
    "avg_cao_3_accu = get_avg_folds(folds_cao_3_accu)\n",
    "print (\"\\nAverage Accuracy with Cao Smoothing (length=3) for all folds:\" , avg_cao_3_accu)\n",
    "\n",
    "avg_cao_5_accu = get_avg_folds(folds_cao_5_accu)\n",
    "print (\"\\nAverage Accuracy with Cao Smoothing (length=5) for all folds:\" , avg_cao_5_accu)\n",
    "\n",
    "avg_krishnan_accu = get_avg_folds(folds_krishnan_accu)\n",
    "print (\"\\nAverage Accuracy with Krishnan Smoothing (delta_t=3) for all folds:\" , avg_krishnan_accu)\n",
    "\n",
    "avg_simple_voting_accu = get_avg_folds(folds_simple_voting_accu)\n",
    "print (\"\\nAverage Accuracy with Simple Voting Scheme Smoothing for all folds:\" , avg_simple_voting_accu)\n",
    "\n",
    "avg_EWV_alpha_5_accu = get_avg_folds(folds_EWV_alpha_5_accu)\n",
    "print (\"\\nAverage Accuracy with EWV Smoothing (alpha=0.05) for all folds:\" , avg_EWV_alpha_5_accu)\n",
    "\n",
    "avg_EWV_alpha_25_accu = get_avg_folds(folds_EWV_alpha_25_accu)\n",
    "print (\"\\nAverage Accuracy with EWV Smoothing (alpha=0.25) for all folds:\" , avg_EWV_alpha_25_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
